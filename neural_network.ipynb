{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course on Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1 - How to create a Neural Network\n",
    "To  create a neural network in Pytorch, you need to create a class that extends the torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SineNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_1 = nn.Linear(1, 3)\n",
    "        self.hidden_layer_2 = nn.Linear(3, 3)\n",
    "\n",
    "        self.output_layer = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_output = self.hidden_layer_1(x)\n",
    "        hidden_output = F.relu(hidden_output)\n",
    "        hidden_output = self.hidden_layer_2(hidden_output)\n",
    "        hidden_output = F.relu(hidden_output)\n",
    "        output = self.output_layer(hidden_output)\n",
    "        return output   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2 How to make an prediction\n",
    "PyTorch expects inputs to be a tensor of type float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.tensor([1]).float()\n",
    "actual_target = torch.tensor([np.sin(1)])\n",
    "sine_network = SineNeuralNetwork()\n",
    "\n",
    "prediction = sine_network(input_data)\n",
    "print(f\"Prediction: {prediction[0]}, Actual: {actual_target[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1 - Create a Neural Network\n",
    "You are tasked to create a fully connected neural network that has the following architecture:\n",
    "- Input Layer: 1 neurons\n",
    "- Hidden Layer: 3 neurons\n",
    "- Output Layer: 1 neuron\n",
    "\n",
    "![Network Structure](images/Network%20Structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Create a neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2 - Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your network and make a prediction here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: How to train a Neural Network\n",
    "When first created, all of the network's weights are set randomly -- the network doesn't \"know\" anything yet. now we're are going to train a neural network; we're going to see how neural networks learn.\n",
    "\n",
    "As with all machine learning tasks, we begin with a set of training data. Each example in the training data consists of some features (the inputs) together with an expected target (the output). Training the network means adjusting its weights in such a way that it can transform the features into the target. \n",
    "\n",
    "With the dataset we're created for the sine wave, we have a set of input values (the x-values) and a set of target values (the sine of the x-values). We want to train the network to transform the input values into the target values.\n",
    "\n",
    "If we can successfully train a network to do that, its weights must represent in some way the relationship between those features and that target as expressed in the training data.\n",
    "\n",
    "When we train the network we must also split the dataset into a training set and a validation set. The training set is used to train the network, while the validation set is used to evaluate the network's performance on data it hasn't seen before. This is an important step to ensure that the network is able to generalize well, that is, to make good predictions on data it wasn't trained on. \n",
    "\n",
    "\n",
    "In addition to the training data, we need two more things:\n",
    "* A \"loss function\" that measures how good the network's predictions are.\n",
    "* An \"optimizer\" that can tell the network how to change its weights.\n",
    "\n",
    "### Loss Function or Criterion\n",
    "We've seen how to design an architecture for a network, but we haven't seen how to tell a network what problem to solve. This is the job of the loss function.\n",
    "\n",
    "The loss function measures the disparity between the the target's true value and the value the model predicts.\n",
    "\n",
    "Different problems needs different loss functions. For example, for a regression problem we can use the Mean Squared Error Loss. For a classification problem, we can use the Cross Entropy Loss.\n",
    "\n",
    "### Optimizer - Stochastic Gradient DescentÂ¶\n",
    "\n",
    "We've described the problem we want the network to solve, but now we need to say how to solve it. This is the job of the optimizer. The optimizer is an algorithm that adjusts the weights to minimize the loss.\n",
    "The optimizer is an algorithm that adjusts the weights to minimize the loss.\n",
    "\n",
    "Virtually all of the optimization algorithms used in deep learning belong to a family called stochastic gradient descent. They are iterative algorithms that train a network in steps. One step of training goes like this:\n",
    "\n",
    "1. Sample some training data and run it through the network to make predictions.\n",
    "2. Measure the loss between the predictions and the true values.\n",
    "3. Finally, adjust the weights in a direction that makes the loss smaller.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Generate some data\n",
    "data = torch.randn(1000, 1)\n",
    "labels = torch.sin(data)\n",
    "train_validation_split = int(0.8 * len(data))\n",
    "\n",
    "# Split the data into training and validation\n",
    "train_input = data[:train_validation_split]\n",
    "train_target = labels[:train_validation_split]\n",
    "\n",
    "validation_input = data[train_validation_split:]\n",
    "validation_target = labels[train_validation_split:]\n",
    "\n",
    "# Create the model, loss function and optimizer\n",
    "model = SineNeuralNetwork()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epoch_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in trange(epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for input, target in zip(train_input, train_target):\n",
    "    \n",
    "        # Forward pass\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_losses.append(epoch_loss/len(train_input))\n",
    "    \n",
    "\n",
    "    # Calculate the validation loss for visualizing the model's performance\n",
    "    validation_loss = 0\n",
    "    for input, target in zip(validation_input, validation_target):\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        validation_loss += loss.item()\n",
    "    \n",
    "    validation_losses.append(validation_loss/len(validation_input))\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.plot(epoch_losses, label='Training loss')\n",
    "plt.plot(validation_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(validation_input)\n",
    "plt.scatter(validation_input, validation_target, label='True values')\n",
    "plt.scatter(validation_input, predictions.detach().numpy(), label='Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Train the Neural Network\n",
    "Try to improve the performance of the neural network by training it on the given dataset.\n",
    "\n",
    "Recommended Steps:\n",
    "* Try to change the number of epochs\n",
    "* Try to change the learning rate\n",
    "* Try to change the neural network architecture\n",
    "  * Add more hidden layers\n",
    "  * Add more neurons to the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Fill in the following values\n",
    "epochs = \n",
    "learning_rate = \n",
    "model = # Your network here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "# Generate some data\n",
    "data = torch.randn(1000, 1)\n",
    "labels = torch.sin(data)\n",
    "train_validation_split = int(0.8 * len(data))\n",
    "\n",
    "# Split the data into training and validation\n",
    "train_input = data[:train_validation_split]\n",
    "train_target = labels[:train_validation_split]\n",
    "\n",
    "validation_input = data[train_validation_split:]\n",
    "validation_target = labels[train_validation_split:]\n",
    "\n",
    "# Create the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in trange(epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for input, target in zip(train_input, train_target):\n",
    "    \n",
    "        # Forward pass\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_losses.append(epoch_loss/len(train_input))\n",
    "    \n",
    "\n",
    "    # Calculate the validation loss for visualizing the model's performance\n",
    "    validation_loss = 0\n",
    "    for input, target in zip(validation_input, validation_target):\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        validation_loss += loss.item()\n",
    "    \n",
    "    validation_losses.append(validation_loss/len(validation_input))\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.plot(epoch_losses, label='Training loss')\n",
    "plt.plot(validation_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: How "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Competition\n",
    "Now it is your turn to compete, join together with the people on your table and try to get the best performance on the dataset.\n",
    "\n",
    "Your goal is to get the highest accuracy on the test dataset.\n",
    "Try to improve the performance of the neural network by training it on the given dataset.\n",
    "\n",
    "Recommended Steps:\n",
    "* Try to change the number of epochs\n",
    "* Try to change the learning rate\n",
    "* Try to change the neural network architecture\n",
    "  * Add more hidden layers\n",
    "  * Add more neurons to the hidden layers\n",
    "* Try to change the optimizer\n",
    "* Try to change the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs =\n",
    "learning_rate =\n",
    "model = \n",
    "criterion =\n",
    "optimizer =\n",
    "train_validation_split_percent = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE ANY CODE IN THIS CELL\n",
    "\n",
    "# Load the data\n",
    "original_data = pd.read_csv('data/winequality-red.csv')\n",
    "\n",
    "# Split the data into input and target\n",
    "target = original_data['quality']\n",
    "data = original_data.drop('quality', axis=1)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "data = torch.tensor(data.values).float()\n",
    "target = torch.tensor(target.values).float()\n",
    "\n",
    "# Split the data into training and validation\n",
    "train_validation_split = int(train_validation_split_percent * len(data))\n",
    "train_input = data[:train_validation_split]\n",
    "train_target = target[:train_validation_split]\n",
    "\n",
    "validation_input = data[train_validation_split:]\n",
    "validation_target = target[train_validation_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create you model here\n",
    "\n",
    "class CompetitionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "epoch_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in trange(epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for input, target in zip(train_input, train_target):\n",
    "    \n",
    "        # Forward pass\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_losses.append(epoch_loss/len(train_input))\n",
    "    \n",
    "\n",
    "    # Calculate the validation loss for visualizing the model's performance\n",
    "    validation_loss = 0\n",
    "    for input, target in zip(validation_input, validation_target):\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        validation_loss += loss.item()\n",
    "    \n",
    "    validation_losses.append(validation_loss/len(validation_input))\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.plot(epoch_losses, label='Training loss')\n",
    "plt.plot(validation_losses, label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test_target = test['quality']\n",
    "test_features = test.drop('quality', axis=1)\n",
    "test_features = torch.tensor(test_features.values).float()\n",
    "test_target = torch.tensor(test_target.values).float()\n",
    "\n",
    "# Calculate the test loss\n",
    "test_loss = 0\n",
    "for input, target in zip(test_features, test_target):\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(f'Test loss: {test_loss/len(test_features)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it3105",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
